# Classification-of-Cats-and-Dogs-using-SVM
**Assignment: Classify Cats and Dogs: Test one or more classifiers using either the classification learner app from Matlab or OpenCV or Python and TensorFlow**

**Project Summary**
![image](https://github.com/aleenarayamajhi/Classification-of-Cats-and-Dogs-using-SVM/assets/126793934/b97648e7-f883-4fe1-8372-71e50a503238)

**Dataset**
For this project, the dataset of 5000 images of dog and cat each were downloaded from Kaggle. Image preprocessing was done to make the dataset suitable for training. A total of 4000 images were chosen for this project (2000 each for cat and dog). The dataset had RGB images which were converted into grayscale so that there’s just one channel instead of three (R, G, and B). Then, the grayscale images were reduced to 100 * 100 pixels size. Converting into grayscale and 100 * 100 pixels size helped to reduce dimension, noise, increase simplicity, uniformity, and memory efficiency. It also helped to simplify feature extraction. Initially, the code was run with RGB images which took comparatively more time to train than with grayscale images. The data was split into training and testing sets using the train_test_split function from scikit-learn.
![image](https://github.com/aleenarayamajhi/Classification-of-Cats-and-Dogs-using-SVM/assets/126793934/9b98c752-ed5c-42b3-8b70-0ab147cddb35)
**Feature Extraction**
HOG alone gave an accuracy of 75% on testing dataset. HOG is a popular technique for capturing shape and edge information in images. For each image, the code computes HOG features using the skimage.feature.hog function. Then, LBP was used instead of HOG, which gave an accuracy of 68%. LBP is another texture feature extraction method that encodes local texture patterns. For each image, the code computes LBP features using the skimage.feature.local_binary_pattern function. Then, to see what the accuracy will be, HOG and LBP features for each image were concatenated together to create a combined feature vector for that image, which gave an accuracy of 78.64%. The extracted features were normalized, and class labels (1 for dogs and 0 for cats) were assigned to the images. The feature vectors and labels were stored in separate lists (feat and label). Then parameters were modified to see if there’s change in the accuracy. When the values like radius and number of sampling points were changed, the accuracy increased. Feature normalization also helped to improve the accuracy. Finally, the accuracy increased to 85.12%. The KNN classifier was also used on the same dataset to check the testing accuracy which reached 84.50% which was close to the result from SVM. 

**Results**
The model achieved a very high training accuracy of 99.22%. This indicates that the model was able to correctly classify most of the training images. The model's performance was evaluated using cross-validation with 5 folds (splits). The mean accuracy is approximately 83.87%, which represents a good estimate of how well the model is likely to perform on new, unseen data. The model achieved a test accuracy of 85.12%, indicating its ability to correctly classify most of the test images. The confusion matrix provided a breakdown of the model's predictions versus the true labels on the test data. 
![image](https://github.com/aleenarayamajhi/Classification-of-Cats-and-Dogs-using-SVM/assets/126793934/763619e2-7541-44bb-b90a-8f7916b9c82d)
